# Vertex AI GGUF Model Server - Requirements
# (for local testing only - production uses Docker image)

# FastAPI server
fastapi>=0.115.0
uvicorn>=0.32.0
pydantic>=2.10.0

# llama.cpp Python bindings (CUDA version)
# For local testing, install the correct version for your GPU:
# pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121
llama-cpp-python>=0.2.90

# Google Cloud clients
google-cloud-storage>=2.14.0
google-auth>=2.25.0

# HTTP client
httpx>=0.27.0
